{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-band Batch Processing Example\n",
    "\n",
    "In this example, we use the `micasense.imageset` class to load a set of directories of images into a list of `micasense.capture` objects, and we iterate over that list saving out each image as an aligned stack of images as separate bands in a single tiff file each. Next, we use the metadata from the original captures to write out a log file of the captures and their locations.  Finally, we use `exiftool` from the command line to inject that metadata into the processed images, allowing us to stitch those images using commercial software such as Pix4D or Agisoft.\n",
    "\n",
    "For an example dataset, download and unzip either sample dataset at https://www.micasense.com/dual-camera-sample-data into your Downloads folder, and ensure the paths below point to the correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Images into ImageSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'List of people with access.png'\t\t    working_package_1\n",
      " Meetings\t\t\t\t\t    working_package_2\n",
      " README.md\t\t\t\t\t    working_package_3\n",
      " Thumbs.db\t\t\t\t\t    working_package_4\n",
      "'treedata (ites-form.ethz.ch) (Y) - Shortcut.lnk'\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input must be >= 2-d.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         panel_reflectance_by_band \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.65\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(panelCap\u001b[38;5;241m.\u001b[39mimages) \u001b[38;5;66;03m#inexact, but quick\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     panel_irradiance \u001b[38;5;241m=\u001b[39m \u001b[43mpanelCap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpanel_irradiance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpanel_reflectance_by_band\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     45\u001b[0m     img_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreflectance\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/imageprocessing/micasense/capture.py:411\u001b[0m, in \u001b[0;36mCapture.panel_irradiance\u001b[0;34m(self, reflectances)\u001b[0m\n\u001b[1;32m    409\u001b[0m irradiance_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpanels):\n\u001b[0;32m--> 411\u001b[0m     mean_irr \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mirradiance_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreflectances\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     irradiance_list\u001b[38;5;241m.\u001b[39mappend(mean_irr)\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m irradiance_list\n",
      "File \u001b[0;32m~/imageprocessing/micasense/panel.py:282\u001b[0m, in \u001b[0;36mPanel.irradiance_mean\u001b[0;34m(self, reflectance)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mirradiance_mean\u001b[39m(\u001b[38;5;28mself\u001b[39m, reflectance):\n\u001b[0;32m--> 282\u001b[0m     radiance_mean, _, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradiance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m radiance_mean \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m/\u001b[39m reflectance\n",
      "File \u001b[0;32m~/imageprocessing/micasense/panel.py:268\u001b[0m, in \u001b[0;36mPanel.radiance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mradiance\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    267\u001b[0m     radiance_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mundistorted(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mradiance())\n\u001b[0;32m--> 268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mregion_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mradiance_img\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpanel_corners\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/imageprocessing/micasense/panel.py:239\u001b[0m, in \u001b[0;36mPanel.region_stats\u001b[0;34m(self, img, region, sat_threshold)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mregion_stats\u001b[39m(\u001b[38;5;28mself\u001b[39m, img, region, sat_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Provide regional statistics for an image over a region\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    Inputs: img is any image ndarray, region is a skimage shape\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    Outputs: mean, std, count, and saturated count tuple for the region\"\"\"\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     rev_panel_pts \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfliplr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# skimage and opencv coords are reversed\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     w, h \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    241\u001b[0m     mask \u001b[38;5;241m=\u001b[39m measure\u001b[38;5;241m.\u001b[39mgrid_points_in_poly((w, h), rev_panel_pts)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mfliplr\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/micasense/lib/python3.8/site-packages/numpy/lib/twodim_base.py:98\u001b[0m, in \u001b[0;36mfliplr\u001b[0;34m(m)\u001b[0m\n\u001b[1;32m     96\u001b[0m m \u001b[38;5;241m=\u001b[39m asanyarray(m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be >= 2-d.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m m[:, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Input must be >= 2-d."
     ]
    }
   ],
   "source": [
    "from ipywidgets import FloatProgress, Layout\n",
    "from IPython.display import display\n",
    "import micasense.imageset as imageset\n",
    "import micasense.capture as capture\n",
    "import os, glob\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "\n",
    "panelNames = None\n",
    "useDLS = True\n",
    "\n",
    "windows_path = r'M:\\working_package_2\\2024_dronecampaign\\01_data\\dronetest\\MicasenseData\\Subset'\n",
    "\n",
    "# Convert to WSL path\n",
    "imagePath = windows_path.replace('M:', '/mnt/m').replace('\\\\', '/')\n",
    "\n",
    "#imagePath = os.path.expanduser(os.path.join('M:', 'working_package_2', '2024_dronecampaign', '01_data', 'dronetest', 'MicasenseData', 'Subset'))\n",
    "panelNames = glob.glob(os.path.join(imagePath,'IMG_0000_1.tif'))\n",
    "\n",
    "outputPath = os.path.join(imagePath,'..','stacks')\n",
    "thumbnailPath = os.path.join(outputPath, '..', 'thumbnails')\n",
    "\n",
    "\n",
    "\n",
    "overwrite = False # Set to False to continue interrupted processing\n",
    "generateThumbnails = True\n",
    "\n",
    "# Allow this code to align both radiance and reflectance images; bu excluding\n",
    "# a definition for panelNames above, radiance images will be used\n",
    "# For panel images, efforts will be made to automatically extract the panel information\n",
    "# but if the panel/firmware is before Altum 1.3.5, RedEdge 5.1.7 the panel reflectance\n",
    "# will need to be set in the panel_reflectance_by_band variable.\n",
    "# Note: radiance images will not be used to properly create NDVI/NDRE images below.\n",
    "if panelNames is not None:\n",
    "    panelCap = capture.Capture.from_filelist(panelNames)\n",
    "else:\n",
    "    panelCap = None\n",
    "\n",
    "if panelCap is not None:\n",
    "    if panelCap.panel_albedo() is not None:\n",
    "        panel_reflectance_by_band = panelCap.panel_albedo()\n",
    "    else:\n",
    "        panel_reflectance_by_band = [0.65]*len(panelCap.images) #inexact, but quick\n",
    "    panel_irradiance = panelCap.panel_irradiance(panel_reflectance_by_band)    \n",
    "    img_type = \"reflectance\"\n",
    "else:\n",
    "    if useDLS:\n",
    "        img_type='reflectance'\n",
    "    else:\n",
    "        img_type = \"radiance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f703cdcd3c45fdad537ba6feed7c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Loading', layout=Layout(width='100%'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 105 ms, total: 1.19 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "## This progress widget is used for display of the long-running process\n",
    "f = FloatProgress(min=0, max=1, layout=Layout(width='100%'), description=\"Loading\")\n",
    "display(f)\n",
    "def update_f(val):\n",
    "    if (val - f.value) > 0.005 or val == 1: #reduces cpu usage from updating the progressbar by 10x\n",
    "        f.value=val\n",
    "\n",
    "%time imgset = imageset.ImageSet.from_directory(imagePath, progress_callback=update_f)\n",
    "update_f(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmapboxgl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_color_stops\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m data, columns \u001b[38;5;241m=\u001b[39m \u001b[43mimgset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_nested_lists\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame\u001b[38;5;241m.\u001b[39mfrom_records(data, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, columns\u001b[38;5;241m=\u001b[39mcolumns)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#Insert your mapbox token here\u001b[39;00m\n",
      "File \u001b[0;32m~/imageprocessing/micasense/imageset.py:109\u001b[0m, in \u001b[0;36mImageSet.as_nested_lists\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03mGet timestamp, latitude, longitude, altitude, capture_id, dls-yaw, dls-pitch, dls-roll, and irradiance from all\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03mCaptures.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m:return: List data from all Captures, List column headers.\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    103\u001b[0m columns \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maltitude\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapture_id\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdls-yaw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdls-pitch\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdls-roll\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    108\u001b[0m ]\n\u001b[0;32m--> 109\u001b[0m irr \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mirr-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(wve) \u001b[38;5;28;01mfor\u001b[39;00m wve \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcenter_wavelengths()]\n\u001b[1;32m    110\u001b[0m columns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m irr\n\u001b[1;32m    111\u001b[0m data \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from mapboxgl.viz import *\n",
    "from mapboxgl.utils import df_to_geojson, create_radius_stops, scale_between\n",
    "from mapboxgl.utils import create_color_stops\n",
    "import pandas as pd\n",
    "\n",
    "data, columns = imgset.as_nested_lists()\n",
    "df = pd.DataFrame.from_records(data, index='timestamp', columns=columns)\n",
    "\n",
    "#Insert your mapbox token here\n",
    "token = 'pk.eyJ1IjoibWljYXNlbnNlIiwiYSI6ImNqYWx5dWNteTJ3cWYzMnBicmZid3g2YzcifQ.Zrq9t7GYocBtBzYyT3P4sw'\n",
    "color_property = 'dls-yaw'\n",
    "color_property = 'altitude'\n",
    "num_color_classes = 8\n",
    "\n",
    "min_val = df[color_property].min()\n",
    "max_val = df[color_property].max()\n",
    "\n",
    "import jenkspy\n",
    "# breaks = jenkspy.jenks_breaks(df[color_property], nb_class=num_color_classes)\n",
    "\n",
    "# color_stops = create_color_stops(breaks,colors='YlOrRd')\n",
    "geojson_data = df_to_geojson(df,columns[3:],lat='latitude',lon='longitude')\n",
    "\n",
    "viz = CircleViz(geojson_data, access_token=token, color_property=color_property,\n",
    "#                 color_stops=color_stops,\n",
    "                center=[df['longitude'].median(),df['latitude'].median()], \n",
    "                zoom=16, height='600px',\n",
    "                style='mapbox://styles/mapbox/satellite-streets-v9')\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define which warp method to use\n",
    "For newer data sets with RigRelatives tags (images captured with RedEdge version 3.4.0 or greater with a valid calibration load, see https://support.micasense.com/hc/en-us/articles/360005428953-Updating-RedEdge-for-Pix4Dfields), we can use the RigRelatives for a simple alignment.\n",
    "\n",
    "For sets without those tags, or sets that require a RigRelatives optimization, we can go through the Alignment.ipynb notebook and get a set of `warp_matrices` that we can use here to align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import float32\n",
    "\n",
    "# Use the warp_matrices derived from the Alignment Tutorial for this RedEdge set without RigRelatives\n",
    "warp_matrices = [array([[ 9.7928989e-01,  1.3615261e-04,  1.9574374e-02],\n",
    "       [-3.7023663e-03,  9.9245304e-01,  2.8355631e+01],\n",
    "       [-1.0651237e-05,  2.6095395e-06,  1.0000000e+00]], dtype=float32), array([[ 9.9525303e-01, -7.0169556e-04, -6.3409243e+00],\n",
    "       [-7.1914408e-05,  9.9811482e-01, -6.2239196e-02],\n",
    "       [-3.6460631e-06,  1.8568957e-06,  1.0000000e+00]], dtype=float32), array([[ 9.9596852e-01, -2.5820474e-03, -1.2950540e+01],\n",
    "       [ 2.8751660e-03,  9.9919146e-01,  2.6645420e+01],\n",
    "       [-1.8280600e-06,  2.3902323e-06,  1.0000000e+00]], dtype=float32), array([[ 9.9592507e-01,  4.5777867e-03,  1.4982515e+01],\n",
    "       [-3.4031910e-03,  9.9773425e-01,  2.2611160e+01],\n",
    "       [-9.0995320e-07,  2.3299665e-06,  1.0000000e+00]], dtype=float32), array([[ 1.0000000e+00,  2.8202797e-20,  8.9091027e-15],\n",
    "       [-5.6938062e-19,  1.0000000e+00,  6.4872178e-15],\n",
    "       [-1.2599002e-21,  1.3424955e-23,  1.0000000e+00]], dtype=float32), array([[ 9.9348122e-01, -1.8129036e-02,  1.1003100e+00],\n",
    "       [ 1.2132729e-02,  9.9091125e-01,  2.8742294e+01],\n",
    "       [-2.9285566e-06, -6.2816152e-06,  1.0000000e+00]], dtype=float32), array([[ 9.8954433e-01, -1.8810771e-02,  1.1892141e+01],\n",
    "       [ 1.3862181e-02,  9.8975760e-01,  2.0044521e+01],\n",
    "       [-4.0683108e-06, -4.2664565e-06,  1.0000000e+00]], dtype=float32), array([[ 9.8794365e-01, -1.2153405e-02,  1.8298512e+01],\n",
    "       [ 8.4343022e-03,  9.8829275e-01,  2.8633160e+01],\n",
    "       [-2.5430195e-06, -3.1491891e-06,  1.0000000e+00]], dtype=float32), array([[ 9.9505156e-01, -1.7393423e-02,  3.6898847e+00],\n",
    "       [ 1.3367594e-02,  9.9287426e-01,  1.8703876e+01],\n",
    "       [-1.3000300e-06, -4.7085673e-06,  1.0000000e+00]], dtype=float32), array([[ 9.9182397e-01, -1.2042225e-02,  1.2686370e+01],\n",
    "       [ 7.6934961e-03,  9.8897797e-01,  2.7970253e+01],\n",
    "       [-9.2655773e-07, -6.0620891e-06,  1.0000000e+00]], dtype=float32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align images and save each capture to a layered tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7142fb6b14c4be980bee622e12b7cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, description='Saving', layout=Layout(width='100%'), max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import exiftool\n",
    "import datetime\n",
    "\n",
    "use_multi_process = True # set to False for single-process saving\n",
    "overwrite_existing = False # skip existing files, set to True to overwrite\n",
    "\n",
    "## This progress widget is used for display of the long-running process\n",
    "f2 = FloatProgress(min=0, max=1, layout=Layout(width='100%'), description=\"Saving\")\n",
    "display(f2)\n",
    "def update_f2(val):\n",
    "    f2.value=val\n",
    "\n",
    "if not os.path.exists(outputPath):\n",
    "    os.makedirs(outputPath)\n",
    "if generateThumbnails and not os.path.exists(thumbnailPath):\n",
    "    os.makedirs(thumbnailPath)\n",
    "    \n",
    "# Save out geojson data so we can open the image capture locations in our GIS\n",
    "with open(os.path.join(outputPath,'imageSet.json'),'w') as f:\n",
    "    f.write(str(geojson_data))\n",
    "    \n",
    "# If we didn't provide a panel above, irradiance set to None will cause DLS data to be used\n",
    "try:\n",
    "    irradiance = panel_irradiance+[0]\n",
    "except NameError:\n",
    "    irradiance = None\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Save all captures in the imageset as aligned stacks\n",
    "imgset.save_stacks(warp_matrices,\n",
    "                     outputPath,\n",
    "                     thumbnailPath,\n",
    "                     irradiance = irradiance,\n",
    "                     multiprocess=use_multi_process, \n",
    "                     overwrite=overwrite_existing, \n",
    "                     progress_callback=update_f2)\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "update_f2(1.0)\n",
    "\n",
    "print(\"Saving time: {}\".format(end_time-start_time))\n",
    "print(\"Alignment+Saving rate: {:.2f} captures per second\".format(float(len(imgset.captures))/float((end_time-start_time).total_seconds())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Metadata from Captures list and save to log.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decdeg2dms(dd):\n",
    "   is_positive = dd >= 0\n",
    "   dd = abs(dd)\n",
    "   minutes,seconds = divmod(dd*3600,60)\n",
    "   degrees,minutes = divmod(minutes,60)\n",
    "   degrees = degrees if is_positive else -degrees\n",
    "   return (degrees,minutes,seconds)\n",
    "\n",
    "header = \"SourceFile,\\\n",
    "GPSDateStamp,GPSTimeStamp,\\\n",
    "GPSLatitude,GpsLatitudeRef,\\\n",
    "GPSLongitude,GPSLongitudeRef,\\\n",
    "GPSAltitude,GPSAltitudeRef,\\\n",
    "FocalLength,\\\n",
    "XResolution,YResolution,ResolutionUnits\\n\"\n",
    "\n",
    "lines = [header]\n",
    "for capture in imgset.captures:\n",
    "    #get lat,lon,alt,time\n",
    "    outputFilename = capture.uuid+'.tif'\n",
    "    fullOutputPath = os.path.join(outputPath, outputFilename)\n",
    "    lat,lon,alt = capture.location()\n",
    "    #write to csv in format:\n",
    "    # IMG_0199_1.tif,\"33 deg 32' 9.73\"\" N\",\"111 deg 51' 1.41\"\" W\",526 m Above Sea Level\n",
    "    latdeg, latmin, latsec = decdeg2dms(lat)\n",
    "    londeg, lonmin, lonsec = decdeg2dms(lon)\n",
    "    latdir = 'North'\n",
    "    if latdeg < 0:\n",
    "        latdeg = -latdeg\n",
    "        latdir = 'South'\n",
    "    londir = 'East'\n",
    "    if londeg < 0:\n",
    "        londeg = -londeg\n",
    "        londir = 'West'\n",
    "    resolution = capture.images[0].focal_plane_resolution_px_per_mm\n",
    "\n",
    "    linestr = '\"{}\",'.format(fullOutputPath)\n",
    "    linestr += capture.utc_time().strftime(\"%Y:%m:%d,%H:%M:%S,\")\n",
    "    linestr += '\"{:d} deg {:d}\\' {:.2f}\"\" {}\",{},'.format(int(latdeg),int(latmin),latsec,latdir[0],latdir)\n",
    "    linestr += '\"{:d} deg {:d}\\' {:.2f}\"\" {}\",{},{:.1f} m Above Sea Level,Above Sea Level,'.format(int(londeg),int(lonmin),lonsec,londir[0],londir,alt)\n",
    "    linestr += '{}'.format(capture.images[0].focal_length)\n",
    "    linestr += '{},{},mm'.format(resolution,resolution)\n",
    "    linestr += '\\n' # when writing in text mode, the write command will convert to os.linesep\n",
    "    lines.append(linestr)\n",
    "\n",
    "fullCsvPath = os.path.join(outputPath,'log.csv')\n",
    "with open(fullCsvPath, 'w') as csvfile: #create CSV\n",
    "    csvfile.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Exiftool from the command line to write metadata to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if os.environ.get('exiftoolpath') is not None:\n",
    "    exiftool_cmd = os.path.normpath(os.environ.get('exiftoolpath'))\n",
    "else:\n",
    "    exiftool_cmd = 'exiftool'\n",
    "        \n",
    "cmd = '{} -csv=\"{}\" -overwrite_original {}'.format(exiftool_cmd, fullCsvPath, outputPath)\n",
    "print(cmd)\n",
    "if(subprocess.check_call(cmd) == 0):\n",
    "    print(\"Successfully updated stack metadata\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "micasense",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
